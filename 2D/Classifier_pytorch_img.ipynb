{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "V7brOxXv3ssW"
   },
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "import torchvision\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZSWQobdlzM0M"
   },
   "outputs": [],
   "source": [
    "casez = []\n",
    "casez = np.append(casez,\"W15.0\")\n",
    "# casez = np.append(casez,\"W15.25\")\n",
    "# casez = np.append(casez,\"W15.5\")\n",
    "# casez = np.append(casez,\"W15.75\")\n",
    "# casez = np.append(casez,\"W16.0\")\n",
    "# casez = np.append(casez,\"W16.2\")\n",
    "# casez = np.append(casez,\"W16.3\")\n",
    "# casez = np.append(casez,\"W16.4\")\n",
    "# casez = np.append(casez,\"W16.5\")\n",
    "# casez = np.append(casez,\"W16.6\")\n",
    "# casez = np.append(casez,\"W16.7\")\n",
    "# casez = np.append(casez,\"W16.8\")\n",
    "# casez = np.append(casez,\"W17.0\")\n",
    "# casez = np.append(casez,\"W17.25\")\n",
    "# casez = np.append(casez,\"W17.5\")\n",
    "# casez = np.append(casez,\"W17.75\")\n",
    "casez = np.append(casez,\"W18.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YyTozVmkzM0N"
   },
   "outputs": [],
   "source": [
    "c = []\n",
    "c = np.append(c,15)\n",
    "# c = np.append(c,15.25)\n",
    "# c = np.append(c,15.5)\n",
    "# c = np.append(c,15.75)\n",
    "# c = np.append(c,16)\n",
    "# c = np.append(c,16.2)\n",
    "# c = np.append(c,16.3)\n",
    "# c = np.append(c,16.4)\n",
    "# c = np.append(c,16.5)\n",
    "# c = np.append(c,16.6)\n",
    "# c = np.append(c,16.7)\n",
    "# c = np.append(c,16.8)\n",
    "# c = np.append(c,17)\n",
    "# c = np.append(c,17.25)\n",
    "# c = np.append(c,17.5)\n",
    "# c = np.append(c,17.75)\n",
    "c = np.append(c,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6pf4PFyrzM0O"
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path(\"/home/physics/phubdf/Data\")\n",
    "os.chdir(path)\n",
    "shutil.rmtree(f\"{path}/workspace\")\n",
    "os.mkdir(f\"{path}/workspace\")\n",
    "\n",
    "for i in range(0,len(casez)):\n",
    "    src = os.listdir(f\"{path}/{casez[i]}\")\n",
    "    for file in src:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            file_name = os.path.join(f\"{path}/{casez[i]}\", file)\n",
    "            if os.path.isfile(file_name):\n",
    "                shutil.copy(file_name, f\"{path}/workspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "z8mOVao_zM0P"
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(f\"{path}/labels\")\n",
    "os.mkdir(f\"{path}/labels\")\n",
    "for i in range(0,len(casez)):\n",
    "    csv_input = pd.read_csv(f'{path}/{casez[i]}/labels.csv')\n",
    "    csv_input.replace(to_replace=0,value=i,inplace = True)\n",
    "    csv_input.to_csv(f'{path}/labels/labels{c[i]}.csv', index=False)\n",
    "\n",
    "\n",
    "src = os.listdir(f'{path}/labels')\n",
    "a = pd.concat([pd.read_csv(f'{path}/labels/{file}') for file in src ], ignore_index=True)\n",
    "a.to_csv(f'{path}/labels/labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yuneJkPG4HP0"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        image = np.asarray(image)\n",
    "        image = np.moveaxis(image, -1, 0)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjNlVkzY4Q7e",
    "outputId": "bcaf14ee-7a22-4a2b-f071-302839fb1836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "data = CustomImageDataset(annotations_file=f\"{path}/labels/labels.csv\",img_dir=f\"{path}/workspace\")\n",
    "print(len(data))\n",
    "#Create Validation set\n",
    "from torch.utils.data import random_split\n",
    "training_data, validation_data, test_data = random_split(data,[320*len(c),60*len(c),20*len(c)])\n",
    "\n",
    "# Create data loaders.\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXf6vf0gGqLN",
    "outputId": "e9f0f098-9452-4132-ad1b-46a23a3d6943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 3, 100, 100])\n",
      "tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]]], dtype=torch.uint8)\n",
      "Labels batch shape: torch.Size([32])\n",
      "Label: tensor([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/warwick/desktop/2018/software/PyTorch/1.10.0-fosscuda-2020b/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:64: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:183.)\n",
      "  return default_collate([torch.as_tensor(b) for b in batch])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(train_features)\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRUtdZRP376z",
    "outputId": "cd232c8c-6a9b-4b4d-b41c-880d6c508683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout(p=0.5, inplace=False)\n",
      "    (10): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=64, bias=False)\n",
      "    (1): Linear(in_features=64, out_features=2, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/warwick/desktop/2018/software/PyTorch/1.10.0-fosscuda-2020b/lib/python3.8/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=0, bias=False),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "        )\n",
    "        \n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=6400, out_features=64,bias=False), \n",
    "            nn.Linear(in_features=64,out_features=len(c),bias=False)\n",
    "        )\n",
    "        \n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1) #flatten\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eJFVTw3B4hhG"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NfqdF69u4pj0"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvWsj3Qm4u9P",
    "outputId": "eddb073d-b5af-4752-8370-11df06fa21c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t Runtime: 10.13s \t Training Loss: 1.981829008460045 \t Validation Loss: 4.174903035163879\n",
      "Validation Loss Decreased(inf--->16.699612) \t Saving The Model\n",
      "Epoch 2 \t Runtime: 9.02s \t Training Loss: 0.729718628525734 \t Validation Loss: 4.1953511238098145\n",
      "\n",
      "\n",
      "Epoch 3 \t Runtime: 9.74s \t Training Loss: 0.7153484672307968 \t Validation Loss: 4.1901469230651855\n",
      "\n",
      "\n",
      "Epoch 4 \t Runtime: 9.56s \t Training Loss: 0.7057170838117599 \t Validation Loss: 4.190192341804504\n",
      "\n",
      "\n",
      "Epoch 5 \t Runtime: 10.85s \t Training Loss: 0.7037197798490524 \t Validation Loss: 4.205447673797607\n",
      "\n",
      "\n",
      "Epoch 6 \t Runtime: 10.25s \t Training Loss: 0.6953256249427795 \t Validation Loss: 4.204384803771973\n",
      "\n",
      "\n",
      "Epoch 7 \t Runtime: 10.22s \t Training Loss: 0.6912533342838287 \t Validation Loss: 4.209101557731628\n",
      "\n",
      "\n",
      "Epoch 8 \t Runtime: 9.52s \t Training Loss: 0.7016356617212296 \t Validation Loss: 4.215372562408447\n",
      "\n",
      "\n",
      "Epoch 9 \t Runtime: 10.67s \t Training Loss: 0.6886534541845322 \t Validation Loss: 4.209285378456116\n",
      "\n",
      "\n",
      "Epoch 10 \t Runtime: 11.95s \t Training Loss: 0.6892684936523438 \t Validation Loss: 4.19716215133667\n",
      "\n",
      "\n",
      "Epoch 11 \t Runtime: 11.33s \t Training Loss: 0.6967130482196808 \t Validation Loss: 4.201832413673401\n",
      "\n",
      "\n",
      "Epoch 12 \t Runtime: 10.41s \t Training Loss: 0.6883532464504242 \t Validation Loss: 4.187349200248718\n",
      "\n",
      "\n",
      "Epoch 13 \t Runtime: 9.47s \t Training Loss: 0.68252212703228 \t Validation Loss: 4.190431594848633\n",
      "\n",
      "\n",
      "Epoch 14 \t Runtime: 9.74s \t Training Loss: 0.6891879111528396 \t Validation Loss: 4.194594740867615\n",
      "\n",
      "\n",
      "Epoch 15 \t Runtime: 10.15s \t Training Loss: 0.67976795732975 \t Validation Loss: 4.200695514678955\n",
      "\n",
      "\n",
      "Epoch 16 \t Runtime: 11.03s \t Training Loss: 0.6826831847429276 \t Validation Loss: 4.206066727638245\n",
      "\n",
      "\n",
      "Epoch 17 \t Runtime: 12.1s \t Training Loss: 0.6860576152801514 \t Validation Loss: 4.1994452476501465\n",
      "\n",
      "\n",
      "Epoch 18 \t Runtime: 12.12s \t Training Loss: 0.6773384243249894 \t Validation Loss: 4.202465057373047\n",
      "\n",
      "\n",
      "Epoch 19 \t Runtime: 12.69s \t Training Loss: 0.6788740247488022 \t Validation Loss: 4.211228013038635\n",
      "\n",
      "\n",
      "Epoch 20 \t Runtime: 13.46s \t Training Loss: 0.6862947344779968 \t Validation Loss: 4.21099054813385\n",
      "\n",
      "\n",
      "Epoch 21 \t Runtime: 13.05s \t Training Loss: 0.6815396994352341 \t Validation Loss: 4.212232232093811\n",
      "\n",
      "\n",
      "Epoch 22 \t Runtime: 13.16s \t Training Loss: 0.6792565792798996 \t Validation Loss: 4.214110851287842\n",
      "\n",
      "\n",
      "Epoch 23 \t Runtime: 11.33s \t Training Loss: 0.674739521741867 \t Validation Loss: 4.2077683210372925\n",
      "\n",
      "\n",
      "Epoch 24 \t Runtime: 12.84s \t Training Loss: 0.6687040030956268 \t Validation Loss: 4.212953209877014\n",
      "\n",
      "\n",
      "Epoch 25 \t Runtime: 14.63s \t Training Loss: 0.6747460246086121 \t Validation Loss: 4.200725555419922\n",
      "\n",
      "\n",
      "Epoch 26 \t Runtime: 12.79s \t Training Loss: 0.6672092527151108 \t Validation Loss: 4.21842098236084\n",
      "\n",
      "\n",
      "Epoch 27 \t Runtime: 12.83s \t Training Loss: 0.666674730181694 \t Validation Loss: 4.225691199302673\n",
      "\n",
      "\n",
      "Epoch 28 \t Runtime: 11.17s \t Training Loss: 0.664917916059494 \t Validation Loss: 4.219489574432373\n",
      "\n",
      "\n",
      "Epoch 29 \t Runtime: 10.37s \t Training Loss: 0.6710162043571473 \t Validation Loss: 4.220044255256653\n",
      "\n",
      "\n",
      "Epoch 30 \t Runtime: 10.8s \t Training Loss: 0.6651000291109085 \t Validation Loss: 4.2244709730148315\n",
      "\n",
      "\n",
      "Epoch 31 \t Runtime: 11.46s \t Training Loss: 0.6655497878789902 \t Validation Loss: 4.224702715873718\n",
      "\n",
      "\n",
      "Epoch 32 \t Runtime: 14.41s \t Training Loss: 0.6578344881534577 \t Validation Loss: 4.219251751899719\n",
      "\n",
      "\n",
      "Epoch 33 \t Runtime: 11.42s \t Training Loss: 0.6573481589555741 \t Validation Loss: 4.236658930778503\n",
      "\n",
      "\n",
      "Epoch 34 \t Runtime: 14.67s \t Training Loss: 0.6582728147506713 \t Validation Loss: 4.2324382066726685\n",
      "\n",
      "\n",
      "Epoch 35 \t Runtime: 12.19s \t Training Loss: 0.6646301597356796 \t Validation Loss: 4.223788261413574\n",
      "\n",
      "\n",
      "Epoch 36 \t Runtime: 13.12s \t Training Loss: 0.6680175542831421 \t Validation Loss: 4.232730388641357\n",
      "\n",
      "\n",
      "Epoch 37 \t Runtime: 12.83s \t Training Loss: 0.659120836853981 \t Validation Loss: 4.22354793548584\n",
      "\n",
      "\n",
      "Epoch 38 \t Runtime: 12.02s \t Training Loss: 0.6687311619520188 \t Validation Loss: 4.2254616022109985\n",
      "\n",
      "\n",
      "Epoch 39 \t Runtime: 12.24s \t Training Loss: 0.6497656017541885 \t Validation Loss: 4.241158962249756\n",
      "\n",
      "\n",
      "Epoch 40 \t Runtime: 13.66s \t Training Loss: 0.6659089863300324 \t Validation Loss: 4.24288022518158\n",
      "\n",
      "\n",
      "Epoch 41 \t Runtime: 12.76s \t Training Loss: 0.6567495048046113 \t Validation Loss: 4.247287273406982\n",
      "\n",
      "\n",
      "Epoch 42 \t Runtime: 15.88s \t Training Loss: 0.6504978507757186 \t Validation Loss: 4.247281908988953\n",
      "\n",
      "\n",
      "Epoch 43 \t Runtime: 12.73s \t Training Loss: 0.6532024413347244 \t Validation Loss: 4.255077838897705\n",
      "\n",
      "\n",
      "Epoch 44 \t Runtime: 11.96s \t Training Loss: 0.6582508623600006 \t Validation Loss: 4.2420490980148315\n",
      "\n",
      "\n",
      "Epoch 45 \t Runtime: 11.78s \t Training Loss: 0.6390929579734802 \t Validation Loss: 4.261348843574524\n",
      "\n",
      "\n",
      "Epoch 46 \t Runtime: 11.81s \t Training Loss: 0.6538598358631134 \t Validation Loss: 4.250640392303467\n",
      "\n",
      "\n",
      "Epoch 47 \t Runtime: 10.81s \t Training Loss: 0.6408801555633545 \t Validation Loss: 4.246520519256592\n",
      "\n",
      "\n",
      "Epoch 48 \t Runtime: 10.79s \t Training Loss: 0.6494376003742218 \t Validation Loss: 4.257177829742432\n",
      "\n",
      "\n",
      "Epoch 49 \t Runtime: 10.38s \t Training Loss: 0.6495213776826858 \t Validation Loss: 4.2507394552230835\n",
      "\n",
      "\n",
      "Epoch 50 \t Runtime: 10.57s \t Training Loss: 0.6554556012153625 \t Validation Loss: 4.243797183036804\n",
      "\n",
      "\n",
      "Total runtime: 584.92s\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "min_valid_loss = np.inf\n",
    "start = time.time()\n",
    "tl = np.array([])\n",
    "vl = np.array([])\n",
    "\n",
    "for e in range(epochs):\n",
    "    st = time.time()\n",
    "    train_loss = 0.0\n",
    "    model.train()     # Optional when not using Model Specific layer\n",
    "    for data, labels in train_dataloader:\n",
    "        data = data.float()\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        target = model(data)\n",
    "        loss = loss_fn(target,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in validation_dataloader:\n",
    "        data = data.float()\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        target = model(data)\n",
    "        loss = loss_fn(target,labels)\n",
    "        valid_loss = loss.item() * data.size(0)\n",
    "    \n",
    "    et = time.time()\n",
    "    rt = et-st\n",
    "\n",
    "    print(f'Epoch {e+1} \\t Runtime: {round(rt,2)}s \\t Training Loss: {train_loss / len(train_dataloader)} \\t Validation Loss: {valid_loss / len(validation_dataloader)}')\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'saved_model.pth')\n",
    "    else:\n",
    "      print(\"\\n\")\n",
    "    \n",
    "    tl = np.append(tl, train_loss / len(train_dataloader))\n",
    "    vl = np.append(vl,valid_loss / len(validation_dataloader))\n",
    "\n",
    "end = time.time()\n",
    "total = end-start\n",
    "print(f\"Total runtime: {round(total,2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "rc87XTcZpCn7",
    "outputId": "c6e697ec-910b-4113-fc5d-e48b0833c2db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0,epochs,1)\n",
    "plt.plot(x+1, tl, \"b+\", label=\"Training loss\")\n",
    "plt.plot(x+1, vl, \"ro\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XBb38sTJ8mdZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "predict = []\n",
    "p = []\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.eval()\n",
    "for i in range(0,20*len(c)):\n",
    "    x, y = test_data[i][0], test_data[i][1]\n",
    "    x = x.reshape(1,3,100,100)\n",
    "    x = torch.from_numpy(x)\n",
    "    x = x.float()\n",
    "    with torch.no_grad():\n",
    "        pred = model(x.cuda()) if torch.cuda.is_available() else model(x)\n",
    "        predicted, actual = pred[0].argmax(0), y \n",
    "        predicted = torch.Tensor.cpu(predicted)\n",
    "        predict = np.append(predict, predicted)\n",
    "        p = np.append(p, actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "wJ2eYK8m9j2L",
    "outputId": "df180e71-50b4-4274-d85a-921bba4e6958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  8]\n",
      " [11  9]]\n",
      "Model Accuracy: 52.5%\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(p, predict)\n",
    "print(cm)\n",
    "np.savetxt(\"cm.csv\", cm, delimiter=\",\")\n",
    "score = round(accuracy_score(p, predict)*100,2)\n",
    "print(f\"Model Accuracy: {score}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIWi_j_xzM0Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
