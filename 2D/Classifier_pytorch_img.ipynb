{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "V7brOxXv3ssW"
   },
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "import torchvision\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZSWQobdlzM0M"
   },
   "outputs": [],
   "source": [
    "casez = []\n",
    "casez = np.append(casez,\"W15.0\")\n",
    "casez = np.append(casez,\"W15.25\")\n",
    "casez = np.append(casez,\"W15.5\")\n",
    "casez = np.append(casez,\"W15.75\")\n",
    "casez = np.append(casez,\"W16.0\")\n",
    "casez = np.append(casez,\"W16.2\")\n",
    "casez = np.append(casez,\"W16.3\")\n",
    "casez = np.append(casez,\"W16.4\")\n",
    "casez = np.append(casez,\"W16.5\")\n",
    "casez = np.append(casez,\"W16.6\")\n",
    "casez = np.append(casez,\"W16.7\")\n",
    "casez = np.append(casez,\"W16.8\")\n",
    "casez = np.append(casez,\"W17.0\")\n",
    "casez = np.append(casez,\"W17.25\")\n",
    "casez = np.append(casez,\"W17.5\")\n",
    "casez = np.append(casez,\"W17.75\")\n",
    "casez = np.append(casez,\"W18.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YyTozVmkzM0N"
   },
   "outputs": [],
   "source": [
    "c = []\n",
    "c = np.append(c,15)\n",
    "c = np.append(c,15.25)\n",
    "c = np.append(c,15.5)\n",
    "c = np.append(c,15.75)\n",
    "c = np.append(c,16)\n",
    "c = np.append(c,16.2)\n",
    "c = np.append(c,16.3)\n",
    "c = np.append(c,16.4)\n",
    "c = np.append(c,16.5)\n",
    "c = np.append(c,16.6)\n",
    "c = np.append(c,16.7)\n",
    "c = np.append(c,16.8)\n",
    "c = np.append(c,17)\n",
    "c = np.append(c,17.25)\n",
    "c = np.append(c,17.5)\n",
    "c = np.append(c,17.75)\n",
    "c = np.append(c,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6pf4PFyrzM0O"
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path(\"/storage/disqs/ML-Anderson3D/Data\")\n",
    "os.chdir(path)\n",
    "shutil.rmtree(f\"{path}/workspace\")\n",
    "os.mkdir(f\"{path}/workspace\")\n",
    "\n",
    "for i in range(0,len(casez)):\n",
    "    src = os.listdir(f\"{path}/{casez[i]}\")\n",
    "    for file in src:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            file_name = os.path.join(f\"{path}/{casez[i]}\", file)\n",
    "            if os.path.isfile(file_name):\n",
    "                shutil.copy(file_name, f\"{path}/workspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z8mOVao_zM0P"
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(f\"{path}/labels\")\n",
    "os.mkdir(f\"{path}/labels\")\n",
    "for i in range(0,len(casez)):\n",
    "    csv_input = pd.read_csv(f'{path}/{casez[i]}/labels.csv')\n",
    "    csv_input.replace(to_replace=0,value=i,inplace = True)\n",
    "    csv_input.to_csv(f'{path}/labels/labels{c[i]}.csv', index=False)\n",
    "\n",
    "\n",
    "src = os.listdir(f'{path}/labels')\n",
    "a = pd.concat([pd.read_csv(f'{path}/labels/{file}') for file in src ], ignore_index=True)\n",
    "a.to_csv(f'{path}/labels/labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yuneJkPG4HP0"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        image = np.asarray(image)\n",
    "        image = np.moveaxis(image, -1, 0)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjNlVkzY4Q7e",
    "outputId": "bcaf14ee-7a22-4a2b-f071-302839fb1836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "data = CustomImageDataset(annotations_file=f\"{path}/labels/labels.csv\",img_dir=f\"{path}/workspace\")\n",
    "print(len(data))\n",
    "#Create Validation set\n",
    "from torch.utils.data import random_split\n",
    "training_data, validation_data, test_data = random_split(data,[320*len(c),60*len(c),20*len(c)])\n",
    "\n",
    "# Create data loaders.\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXf6vf0gGqLN",
    "outputId": "e9f0f098-9452-4132-ad1b-46a23a3d6943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 3, 100, 100])\n",
      "tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]]], dtype=torch.uint8)\n",
      "Labels batch shape: torch.Size([32])\n",
      "Label: tensor([ 6,  4, 16,  1,  2,  0, 14, 10,  7, 12,  6, 10, 10,  3, 15, 10,  5, 15,\n",
      "         8, 10,  0, 16,  7,  5, 16,  6, 11, 12, 16, 15,  8,  3])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(train_features)\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRUtdZRP376z",
    "outputId": "cd232c8c-6a9b-4b4d-b41c-880d6c508683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=17, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model = models.resnet18()\n",
    "model.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "model.fc = nn.Linear(in_features=512,out_features=(len(c)), bias=True)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "eJFVTw3B4hhG"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "NfqdF69u4pj0"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvWsj3Qm4u9P",
    "outputId": "eddb073d-b5af-4752-8370-11df06fa21c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t Runtime: 19.52s \t Training Loss: 2.862275791168213 \t Validation Loss: 2.4650107324123383\n",
      "Validation Loss Decreased(inf--->78.880343) \t Saving The Model\n",
      "Epoch 2 \t Runtime: 19.82s \t Training Loss: 2.8245709517422846 \t Validation Loss: 2.459673911333084\n",
      "Validation Loss Decreased(78.880343--->78.709565) \t Saving The Model\n",
      "Epoch 3 \t Runtime: 19.83s \t Training Loss: 2.8051252982195685 \t Validation Loss: 2.453853517770767\n",
      "Validation Loss Decreased(78.709565--->78.523313) \t Saving The Model\n",
      "Epoch 4 \t Runtime: 19.94s \t Training Loss: 2.7867092595380893 \t Validation Loss: 2.448232352733612\n",
      "Validation Loss Decreased(78.523313--->78.343435) \t Saving The Model\n",
      "Epoch 5 \t Runtime: 20.68s \t Training Loss: 2.768707003312952 \t Validation Loss: 2.4424102902412415\n",
      "Validation Loss Decreased(78.343435--->78.157129) \t Saving The Model\n",
      "Epoch 6 \t Runtime: 22.95s \t Training Loss: 2.750780494072858 \t Validation Loss: 2.436170369386673\n",
      "Validation Loss Decreased(78.157129--->77.957452) \t Saving The Model\n",
      "Epoch 7 \t Runtime: 19.89s \t Training Loss: 2.732663174236522 \t Validation Loss: 2.428539603948593\n",
      "Validation Loss Decreased(77.957452--->77.713267) \t Saving The Model\n",
      "Epoch 8 \t Runtime: 19.82s \t Training Loss: 2.7141812997705794 \t Validation Loss: 2.420976012945175\n",
      "Validation Loss Decreased(77.713267--->77.471232) \t Saving The Model\n",
      "Epoch 9 \t Runtime: 20.0s \t Training Loss: 2.6951291350757374 \t Validation Loss: 2.412367880344391\n",
      "Validation Loss Decreased(77.471232--->77.195772) \t Saving The Model\n",
      "Epoch 10 \t Runtime: 20.17s \t Training Loss: 2.67541427191566 \t Validation Loss: 2.403801679611206\n",
      "Validation Loss Decreased(77.195772--->76.921654) \t Saving The Model\n",
      "Total runtime: 207.9s\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "min_valid_loss = np.inf\n",
    "start = time.time()\n",
    "tl = np.array([])\n",
    "vl = np.array([])\n",
    "\n",
    "for e in range(epochs):\n",
    "    st = time.time()\n",
    "    train_loss = 0.0\n",
    "    model.train()     # Optional when not using Model Specific layer\n",
    "    for data, labels in train_dataloader:\n",
    "        data = data.float()\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        target = model(data)\n",
    "        loss = loss_fn(target,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in validation_dataloader:\n",
    "        data = data.float()\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        target = model(data)\n",
    "        loss = loss_fn(target,labels)\n",
    "        valid_loss = loss.item() * data.size(0)\n",
    "    \n",
    "    et = time.time()\n",
    "    rt = et-st\n",
    "\n",
    "    print(f'Epoch {e+1} \\t Runtime: {round(rt,2)}s \\t Training Loss: {train_loss / len(train_dataloader)} \\t Validation Loss: {valid_loss / len(validation_dataloader)}')\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'saved_model.pth')\n",
    "    else:\n",
    "      print(\" \")\n",
    "    \n",
    "    tl = np.append(tl, train_loss / len(train_dataloader))\n",
    "    vl = np.append(vl,valid_loss / len(validation_dataloader))\n",
    "\n",
    "end = time.time()\n",
    "total = end-start\n",
    "print(f\"Total runtime: {round(total,2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "rc87XTcZpCn7",
    "outputId": "c6e697ec-910b-4113-fc5d-e48b0833c2db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0,epochs,1)\n",
    "plt.plot(x+1, tl, \"b+\", label=\"Training loss\")\n",
    "np.savetxt(f\"csv/tl-C{len(c)}-N400-{datetime.now()}.csv\", tl, delimiter=\",\")\n",
    "plt.plot(x+1, vl, \"ro\", label=\"Validation loss\")\n",
    "np.savetxt(f\"csv/vl-C{len(c)}-N400-{datetime.now()}.csv\", vl, delimiter=\",\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "XBb38sTJ8mdZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "predict = []\n",
    "p = []\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.eval()\n",
    "for i in range(0,20*len(c)):\n",
    "    x, y = test_data[i][0], test_data[i][1]\n",
    "    x = x.reshape(1,3,100,100)\n",
    "    x = torch.from_numpy(x)\n",
    "    x = x.float()\n",
    "    with torch.no_grad():\n",
    "        pred = model(x.cuda()) if torch.cuda.is_available() else model(x)\n",
    "        predicted, actual = pred[0].argmax(0), y \n",
    "        predicted = torch.Tensor.cpu(predicted)\n",
    "        predict = np.append(predict, predicted)\n",
    "        p = np.append(p, actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "wJ2eYK8m9j2L",
    "outputId": "df180e71-50b4-4274-d85a-921bba4e6958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  8  4  1  0  0  2  2  0  0  1  0  4  0  0  1  0]\n",
      " [ 4  3  0  1  0  0  0  2  0  1  0  0  1  0  1  0  0]\n",
      " [ 4  3  4  0  0  2  0  0  0  1  0  0  2  0  0  0  0]\n",
      " [ 6  3  0  3  0  3  0  0  0  1  0  0  1  0  0  1  0]\n",
      " [ 3  4  0  0  1  3  0  0  0  0  1  0  0  0  1  0  0]\n",
      " [ 3  6  3  0  0  1  0  0  0  1  2  0  1  0  2  2  0]\n",
      " [ 2  2  1  0  0  1  0  0  0  0  1  1  2  0  1  6  1]\n",
      " [ 3  0  5  0  0  0  1  0  0  0  0  0  2  1  1  2  1]\n",
      " [ 4  2  5  1  0  2  2  0  0  0  1  0  1  0  0  3  0]\n",
      " [ 1  4  1  2  1  0  2  0  0  2  3  0  1  0  0  2  2]\n",
      " [ 5  4  6  0  0  3  0  0  0  0  2  0  1  0  2  3  0]\n",
      " [ 2  3  3  0  1  2  0  0  0  1  0  0  4  0  1  3  2]\n",
      " [ 1  0  0  1  0  0  2  0  0  0  3  0  4  0  2  2  1]\n",
      " [ 0  1  3  1  0  2  0  0  0  0  0  1  5  0  0  8  0]\n",
      " [ 0  0  1  2  0  1  0  0  0  1  1  0  3  0  2  6  3]\n",
      " [ 1  0  0  0  0  1  0  0  0  0  3  0  6  0  5 11  1]\n",
      " [ 0  0  2  0  1  3  0  0  0  0  0  0  2  0  0 13  1]]\n",
      "Model Accuracy: 11.47%\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(p, predict)\n",
    "print(cm)\n",
    "np.savetxt(f\"csv/cm-C{len(c)}-N400-{datetime.now()}.csv\", cm, delimiter=\",\")\n",
    "score = round(accuracy_score(p, predict)*100,2)\n",
    "print(f\"Model Accuracy: {score}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIWi_j_xzM0Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
