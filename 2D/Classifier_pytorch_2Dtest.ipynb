{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "V7brOxXv3ssW"
   },
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "import torchvision\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZSWQobdlzM0M"
   },
   "outputs": [],
   "source": [
    "casez = [\"Ext\",\"Loc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YyTozVmkzM0N"
   },
   "outputs": [],
   "source": [
    "c = [\"Ext\",\"Loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6pf4PFyrzM0O"
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path(\"/home/physics/phubdf/Test_Train_Data\")\n",
    "os.chdir(path)\n",
    "shutil.rmtree(f\"{path}/workspace\")\n",
    "os.mkdir(f\"{path}/workspace\")\n",
    "\n",
    "for i in range(0,len(casez)):\n",
    "    src = os.listdir(f\"{path}/{casez[i]}\")\n",
    "    for file in src:\n",
    "        if file.endswith(\".raw\"):\n",
    "            file_name = os.path.join(f\"{path}/{casez[i]}\", file)\n",
    "            if os.path.isfile(file_name):\n",
    "                shutil.copy(file_name, f\"{path}/workspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "z8mOVao_zM0P"
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(f\"{path}/labels\")\n",
    "os.mkdir(f\"{path}/labels\")\n",
    "for i in range(0,len(casez)):\n",
    "    csv_input = pd.read_csv(f'{path}/{casez[i]}/labels.csv')\n",
    "    csv_input.replace(to_replace=0,value=i,inplace = True)\n",
    "    csv_input.to_csv(f'{path}/labels/labels{c[i]}.csv', index=False)\n",
    "\n",
    "\n",
    "src = os.listdir(f'{path}/labels')\n",
    "a = pd.concat([pd.read_csv(f'{path}/labels/{file}') for file in src ], ignore_index=True)\n",
    "a.to_csv(f'{path}/labels/labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yuneJkPG4HP0"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = np.loadtxt(f\"{img_path}\")\n",
    "        image = image.reshape(1,100,100)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjNlVkzY4Q7e",
    "outputId": "bcaf14ee-7a22-4a2b-f071-302839fb1836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "data = CustomImageDataset(annotations_file=f\"{path}/labels/labels.csv\",img_dir=f\"{path}/workspace\")\n",
    "print(len(data))\n",
    "#Create Validation set\n",
    "from torch.utils.data import random_split\n",
    "training_data, validation_data, test_data = random_split(data,[1600,300,100])\n",
    "\n",
    "# Create data loaders.\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXf6vf0gGqLN",
    "outputId": "e9f0f098-9452-4132-ad1b-46a23a3d6943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 100, 100])\n",
      "tensor([[[[4.8375e-03, 5.4592e-03, 4.9253e-03,  ..., 4.6378e-03,\n",
      "           4.8158e-03, 4.6185e-03],\n",
      "          [5.3517e-03, 5.1188e-03, 5.2807e-03,  ..., 5.1043e-03,\n",
      "           5.3607e-03, 5.0830e-03],\n",
      "          [5.1891e-03, 5.3081e-03, 4.6058e-03,  ..., 5.3367e-03,\n",
      "           5.3026e-03, 4.9194e-03],\n",
      "          ...,\n",
      "          [5.2388e-03, 5.4955e-03, 4.5245e-03,  ..., 4.9046e-03,\n",
      "           4.9402e-03, 5.2020e-03],\n",
      "          [5.2608e-03, 4.7773e-03, 4.5089e-03,  ..., 4.9777e-03,\n",
      "           5.4147e-03, 5.0160e-03],\n",
      "          [4.5041e-03, 4.8294e-03, 5.1805e-03,  ..., 5.3094e-03,\n",
      "           4.8045e-03, 5.4651e-03]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          ...,\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05]]],\n",
      "\n",
      "\n",
      "        [[[5.4696e-03, 4.5450e-03, 4.6076e-03,  ..., 4.6042e-03,\n",
      "           4.6861e-03, 5.4258e-03],\n",
      "          [5.1971e-03, 4.9909e-03, 5.3398e-03,  ..., 4.8319e-03,\n",
      "           4.9313e-03, 5.2127e-03],\n",
      "          [5.0622e-03, 4.8586e-03, 4.5243e-03,  ..., 5.0910e-03,\n",
      "           5.2587e-03, 5.2065e-03],\n",
      "          ...,\n",
      "          [4.9906e-03, 5.3832e-03, 5.1844e-03,  ..., 4.6303e-03,\n",
      "           4.6460e-03, 4.7482e-03],\n",
      "          [5.3682e-03, 5.0362e-03, 5.2187e-03,  ..., 5.4417e-03,\n",
      "           5.1164e-03, 5.3780e-03],\n",
      "          [5.4937e-03, 5.4987e-03, 4.5771e-03,  ..., 4.5533e-03,\n",
      "           5.0609e-03, 5.1639e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          ...,\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05]]],\n",
      "\n",
      "\n",
      "        [[[4.6422e-03, 5.0574e-03, 4.8000e-03,  ..., 5.4688e-03,\n",
      "           4.7505e-03, 5.2104e-03],\n",
      "          [4.6403e-03, 5.1123e-03, 4.9624e-03,  ..., 4.5061e-03,\n",
      "           4.5823e-03, 4.6712e-03],\n",
      "          [4.8567e-03, 4.5176e-03, 5.3822e-03,  ..., 5.1922e-03,\n",
      "           5.4013e-03, 4.7048e-03],\n",
      "          ...,\n",
      "          [5.2465e-03, 5.2450e-03, 4.6211e-03,  ..., 4.8477e-03,\n",
      "           4.6330e-03, 4.8248e-03],\n",
      "          [4.6415e-03, 4.5804e-03, 5.3787e-03,  ..., 5.1169e-03,\n",
      "           4.5348e-03, 4.9787e-03],\n",
      "          [4.5539e-03, 4.6076e-03, 4.8063e-03,  ..., 4.9154e-03,\n",
      "           5.2676e-03, 4.6715e-03]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          ...,\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05],\n",
      "          [1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05,\n",
      "           1.0000e-05, 1.0000e-05]]]], dtype=torch.float64)\n",
      "Labels batch shape: torch.Size([32])\n",
      "Label: tensor([0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(train_features)\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model = models.resnet18()\n",
    "model.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "model.fc = nn.Linear(in_features=512,out_features=2,bias=True)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "eJFVTw3B4hhG"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "NfqdF69u4pj0"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvWsj3Qm4u9P",
    "outputId": "eddb073d-b5af-4752-8370-11df06fa21c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t Runtime: 197.94s \t Training Loss: 0.3738549408316612 \t Validation Loss: 0.8798331499099732\n",
      "Validation Loss Decreased(inf--->8.798331) \t Saving The Model\n",
      "Epoch 2 \t Runtime: 186.28s \t Training Loss: 0.18044482424855232 \t Validation Loss: 0.30052528381347654\n",
      "Validation Loss Decreased(8.798331--->3.005253) \t Saving The Model\n",
      "Epoch 3 \t Runtime: 233.83s \t Training Loss: 0.1289166444540024 \t Validation Loss: 0.15269603133201598\n",
      "Validation Loss Decreased(3.005253--->1.526960) \t Saving The Model\n",
      "Epoch 4 \t Runtime: 195.72s \t Training Loss: 0.09958625867962838 \t Validation Loss: 0.11716851890087128\n",
      "Validation Loss Decreased(1.526960--->1.171685) \t Saving The Model\n",
      "Epoch 5 \t Runtime: 185.24s \t Training Loss: 0.07946996256709099 \t Validation Loss: 0.09179451763629913\n",
      "Validation Loss Decreased(1.171685--->0.917945) \t Saving The Model\n",
      "Epoch 6 \t Runtime: 185.0s \t Training Loss: 0.06462785303592682 \t Validation Loss: 0.07285053580999375\n",
      "Validation Loss Decreased(0.917945--->0.728505) \t Saving The Model\n",
      "Epoch 7 \t Runtime: 185.32s \t Training Loss: 0.053319128975272176 \t Validation Loss: 0.058587062358856204\n",
      "Validation Loss Decreased(0.728505--->0.585871) \t Saving The Model\n",
      "Epoch 8 \t Runtime: 187.57s \t Training Loss: 0.044568694420158865 \t Validation Loss: 0.04781729131937027\n",
      "Validation Loss Decreased(0.585871--->0.478173) \t Saving The Model\n",
      "Epoch 9 \t Runtime: 189.36s \t Training Loss: 0.03773167490959167 \t Validation Loss: 0.039619289338588715\n",
      "Validation Loss Decreased(0.478173--->0.396193) \t Saving The Model\n",
      "Epoch 10 \t Runtime: 186.49s \t Training Loss: 0.032334129046648744 \t Validation Loss: 0.03330526873469353\n",
      "Validation Loss Decreased(0.396193--->0.333053) \t Saving The Model\n",
      "Total runtime: 1940.25s\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "min_valid_loss = np.inf\n",
    "start = time.time()\n",
    "tl = np.array([])\n",
    "vl = np.array([])\n",
    "\n",
    "for e in range(epochs):\n",
    "    st = time.time()\n",
    "    train_loss = 0.0\n",
    "    model.train()     # Optional when not using Model Specific layer\n",
    "    for data, labels in train_dataloader:\n",
    "        data = data.float()\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        target = model(data)\n",
    "        loss = loss_fn(target,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in validation_dataloader:\n",
    "        data = data.float()\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        target = model(data)\n",
    "        loss = loss_fn(target,labels)\n",
    "        valid_loss = loss.item() * data.size(0)\n",
    "    \n",
    "    et = time.time()\n",
    "    rt = et-st\n",
    "\n",
    "    print(f'Epoch {e+1} \\t Runtime: {round(rt,2)}s \\t Training Loss: {train_loss / len(train_dataloader)} \\t Validation Loss: {valid_loss / len(validation_dataloader)}')\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'saved_model.pth')\n",
    "    else:\n",
    "      print(\" \")\n",
    "    \n",
    "    tl = np.append(tl, train_loss / len(train_dataloader))\n",
    "    vl = np.append(vl,valid_loss / len(validation_dataloader))\n",
    "\n",
    "end = time.time()\n",
    "total = end-start\n",
    "print(f\"Total runtime: {round(total,2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "rc87XTcZpCn7",
    "outputId": "c6e697ec-910b-4113-fc5d-e48b0833c2db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0,epochs,1)\n",
    "plt.plot(x+1, tl, \"b+\", label=\"Training loss\")\n",
    "np.savetxt(f\"tl-E0.1-L0.00001-{datetime.now()}.csv\", tl, delimiter=\",\")\n",
    "plt.plot(x+1, vl, \"ro\", label=\"Validation loss\")\n",
    "np.savetxt(f\"vl-E0.1-L0.00001-{datetime.now()}.csv\", vl, delimiter=\",\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "XBb38sTJ8mdZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "predict = []\n",
    "p = []\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.eval()\n",
    "for i in range(0,20*len(c)):\n",
    "    x, y = test_data[i][0], test_data[i][1]\n",
    "    x = x.reshape(1,1,100,100)\n",
    "    x = torch.from_numpy(x)\n",
    "    x = x.float()\n",
    "    with torch.no_grad():\n",
    "        pred = model(x.cuda()) if torch.cuda.is_available() else model(x)\n",
    "        predicted, actual = pred[0].argmax(0), y \n",
    "        predicted = torch.Tensor.cpu(predicted)\n",
    "        predict = np.append(predict, predicted)\n",
    "        p = np.append(p, actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "wJ2eYK8m9j2L",
    "outputId": "df180e71-50b4-4274-d85a-921bba4e6958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  0]\n",
      " [ 0 17]]\n",
      "Model Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(p, predict)\n",
    "print(cm)\n",
    "np.savetxt(f\"cm-E0.1-L0.00001-{datetime.now()}.csv\", cm, delimiter=\",\")\n",
    "score = round(accuracy_score(p, predict)*100,2)\n",
    "print(f\"Model Accuracy: {score}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIWi_j_xzM0Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
